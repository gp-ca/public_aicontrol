{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01885fcc",
   "metadata": {},
   "source": [
    "# Initial preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c35632",
   "metadata": {},
   "source": [
    "## Validate ground truth (DQC1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23b01f0",
   "metadata": {},
   "source": [
    "**Evidence**\t<br>\n",
    "Events selected based on their cell type stored in the class matrices were matched with  the exported events from manual gating of the same cell type.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b221dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pathlib\n",
    "import os\n",
    "import glob\n",
    "from assets.functions import open_fcs, importFCS_compensate, \\\n",
    "    preprocess_raw_data\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de080c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load FCS files and class matrices generated with mathematica\n",
    "fcsDir = pathlib.Path(r\"data\\\\fcs_data\")\n",
    "fcsFileNames = glob.glob(f\"{fcsDir}\\\\*.fcs\")\n",
    "csvDir = pathlib.Path(r\"data\\\\data_classified_by_expert1\\\\class_matrices_all_classes\")\n",
    "fcsDir = pathlib.Path(r\"data\\\\data_classified_by_expert1\")\n",
    "EXT_CSV = \"*.csv\"\n",
    "EXT_FCS = \"*.fcs\"\n",
    "\n",
    "# load class matrix names\n",
    "csvFileNames = [file \n",
    "                for csv, subdir, files in os.walk(csvDir) \n",
    "                for file in glob.glob(os.path.join(csv, EXT_CSV))]\n",
    "\n",
    "# load fcs file names\n",
    "exclude_strings = ['Lympho', 'BP', 'NKP', 'TP', 'T4P', 'T8P']\n",
    "fcsFileNames = [file\n",
    "                for path, subdir, files in os.walk(fcsDir)\n",
    "                for file in glob.glob(os.path.join(path, EXT_FCS))\n",
    "                if not any(ex_string in os.path.basename(file) for ex_string in exclude_strings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c6e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load FCS files from manual gating\n",
    "# each \"_celltype_\" FCS file contains only subset as determined through manual gating in BD FACSDiva v8.0.2\n",
    "fcsSubDir = pathlib.Path(r\"data\\\\data_classified_by_expert1\")\n",
    "EXT = \"*.fcs\"\n",
    "LymphofcsFileNames = [file \n",
    "                for fcs, subdir, files in os.walk(fcsSubDir) \n",
    "                for file in glob.glob(os.path.join(fcs, EXT)) if '_Lympho_' in file]\n",
    "BPfcsFileNames = [file \n",
    "                for fcs, subdir, files in os.walk(fcsSubDir) \n",
    "                for file in glob.glob(os.path.join(fcs, EXT)) if '_BP_' in file]\n",
    "NKPfcsFileNames = [file \n",
    "                for fcs, subdir, files in os.walk(fcsSubDir) \n",
    "                for file in glob.glob(os.path.join(fcs, EXT)) if '_NKP_' in file]\n",
    "TPfcsFileNames = [file \n",
    "                for fcs, subdir, files in os.walk(fcsSubDir) \n",
    "                for file in glob.glob(os.path.join(fcs, EXT)) if '_TP_' in file]\n",
    "T4PfcsFileNames = [file \n",
    "                for fcs, subdir, files in os.walk(fcsSubDir) \n",
    "                for file in glob.glob(os.path.join(fcs, EXT)) if '_T4P_' in file]\n",
    "T8PfcsFileNames = [file \n",
    "                for fcs, subdir, files in os.walk(fcsSubDir) \n",
    "                for file in glob.glob(os.path.join(fcs, EXT)) if '_T8P_' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "431d4682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lympho\n",
      "checked #file: 100\n",
      "BP\n",
      "checked #file: 100\n",
      "NKP\n",
      "checked #file: 100\n",
      "TP\n",
      "checked #file: 100\n",
      "T4P\n",
      "checked #file: 100\n",
      "T8P\n",
      "checked #file: 100\n"
     ]
    }
   ],
   "source": [
    "# define cell subsets of interest\n",
    "cell_subsets_of_interst = ['Lympho', 'BP', 'NKP', 'TP', 'T4P', 'T8P']\n",
    "# create list of all manually gated fcs filenames\n",
    "fcsSubFileNames = [LymphofcsFileNames, BPfcsFileNames, NKPfcsFileNames, TPfcsFileNames, \n",
    "                   T4PfcsFileNames, T8PfcsFileNames]\n",
    "\n",
    "# select cells in FCS file based on condition in class matrix (e.g. Lympho==1) \n",
    "# and check if the selection is equal to the \"_celltype_\" FCS file from BD FACSDiva v8.0.2\n",
    "\n",
    "for celltype in range(6):\n",
    "    print(cell_subsets_of_interst[celltype])\n",
    "    for i in range(100):\n",
    "        # rearrange column \"Time\" in subset FCS files equal to original fcs file\n",
    "        if (open_fcs(fcsSubFileNames[celltype][i])[:,[10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] ==\n",
    "            open_fcs(fcsFileNames[i])[pd.read_csv(csvFileNames[i])[cell_subsets_of_interst[celltype]]==1]).all() == False:\n",
    "            print('Error in class matrix detected', 'in', cell_subsets_of_interst[celltype], \n",
    "                  ' #file ', i+1)\n",
    "        else:\n",
    "            print('checked #file:', i+1, end=\"\\r\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a301c1c7",
   "metadata": {},
   "source": [
    "**Conclusion**\t<br>\n",
    "The cell types stored in the class matrices align with the expert's manual gating results (ground truth)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379bb322",
   "metadata": {},
   "source": [
    "## Data preprocessing for subsequent model implementation data quality assurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ea6fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct for fluorescence overlap\n",
    "\n",
    "# manually assign fluorescent channels in spillover matrix (copy paste from metadata, see also header in fcsparser)\n",
    "spilloverColNames = ['FITC-A','PE-A','PerCP-A','PE-Cy7-A','APC-A','APC-H7-A','Pacific Blue-A','AmCyan-A']\n",
    "\n",
    "# manually generate spillover matrix (copy paste from metadata, see also header in fcsparser)\n",
    "spilloverList = np.array([1,0.14499559729967626,0.030818902260052756,0.002935133548576454,\n",
    "                          0.00025242166432390677,0,0,0.013892965463261886,0.017747527114277597,1,\n",
    "                          0.2512006615565677,0.01936961292579762,0.0004649979391065989,\n",
    "                          0.00022497163272324362,0,0,0,0,1,0.0782845473110962,0.08909214832730754,\n",
    "                          0.015777378258149535,0,0,0.0014724232592962347,0.010032443224357373,\n",
    "                          0.03608684801597224,1,0.0007297228679969534,0.09257233272762264,0,0,0,0,\n",
    "                          0.00822608423900849,0.0009264873033695553,1,0.06805489109035323,0,0,\n",
    "                          0.00019294268176635863,0.0001929426817663584,0.0005788280452990768,\n",
    "                          0.0143742297915937,0.03086311021734536,1,0,0,0,0,0,0.00027757216876387914,\n",
    "                          0.0008354928209373731,0.001008512177880296,1,0.2970022205773495,\n",
    "                          0.11682892906815066,0.028685674547983413,0.007823365785813646,\n",
    "                          0.0015646731571627294,0,0,0.08240611961057033,1])\n",
    "\n",
    "# reshape spillover matrix (8 fluorescence markers)\n",
    "spilloverMatrix = spilloverList.reshape(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcfc8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load FCS files and compensate fluoresent data\n",
    "nFiles = 100\n",
    "dataset = []\n",
    "\n",
    "for i in range(0, nFiles):\n",
    "    header_loop, data_loop = importFCS_compensate(fcsFileNames[i], spilloverMatrix)\n",
    "    dataset.append(data_loop[:,1:])  # remove channel 'Time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456dfabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load class matrices storing event labels\n",
    "labelset = []\n",
    "# load training class information of .csv-file n\n",
    "for i in range(0, nFiles):\n",
    "    labels_loop = pd.read_csv(csvFileNames[i])\n",
    "    labelset.append(labels_loop.iloc[:, 1:])  # [...].iloc[:, 1:] to get rid of event_number which is redunant with row number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b3e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all compensated events in the fcs files and thier valid cell type information as pickle\n",
    "\n",
    "raw_data_preprocessed_list = []\n",
    "for i in range(100):\n",
    "    raw_data_preprocessed_list.append(preprocess_raw_data(dataset[i], labelset[i], i))\n",
    "raw_data_preprocessed = pd.concat(raw_data_preprocessed_list)\n",
    "raw_data_preprocessed.to_pickle(pathlib.Path(r'data\\\\processed_data\\\\raw_data_preprocessed.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
